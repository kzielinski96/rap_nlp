{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "durable-arrival",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "analyzed-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pathlib\n",
    "import re\n",
    "import string\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_text as tf_text\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "amber-worcester",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset/tf/main_lines_verses.csv\", encoding= 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "brutal-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "powerful-wichita",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name</th>\n",
       "      <th>line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89780</th>\n",
       "      <td>Playboi Carti</td>\n",
       "      <td>Just stay focused on your mission, and don't e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59970</th>\n",
       "      <td>Young Buck</td>\n",
       "      <td>Follow the sparkles on the bottles and I appear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38489</th>\n",
       "      <td>Dr. Dre</td>\n",
       "      <td>Why a motherfuckin' brother is hard to find</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13491</th>\n",
       "      <td>Big Pun</td>\n",
       "      <td>I'm like the beast with a warrant, far from a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41055</th>\n",
       "      <td>Drake</td>\n",
       "      <td>Man, someone just gave you the run-around</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         artist_name                                               line\n",
       "89780  Playboi Carti  Just stay focused on your mission, and don't e...\n",
       "59970     Young Buck    Follow the sparkles on the bottles and I appear\n",
       "38489        Dr. Dre        Why a motherfuckin' brother is hard to find\n",
       "13491        Big Pun  I'm like the beast with a warrant, far from a ...\n",
       "41055          Drake          Man, someone just gave you the run-around"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "several-eleven",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Eminem              8530\n",
       "Ice Cube            4490\n",
       "Kendrick Lamar      4320\n",
       "Juice WRLD          3941\n",
       "Nas                 3872\n",
       "                    ... \n",
       "Dr. Dre & MC Ren       2\n",
       "Tego Calderon          2\n",
       "Mae Day                1\n",
       "T3                     1\n",
       "Skyzoo                 1\n",
       "Name: artist_name, Length: 1262, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['artist_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "proud-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.replace(\"Jay-Z\", \"JAY-Z\", inplace=True)\n",
    "# df.replace(\"KRS-One\", \"KRS-ONE\", inplace=True)\n",
    "# df.replace(\"LL Cool J\", \"L.L. Cool J\", inplace=True)\n",
    "# df.replace(\"Royce da 5'9\", \"Royce Da 5'9\", inplace=True)\n",
    "df.replace(\"Notorious B.I.G.\", \"The Notorious B.I.G.\", inplace=True)\n",
    "df = df.groupby('artist_name').filter(lambda x : len(x)>1000)\n",
    "df = df[df['line'].apply(lambda x: len(x.split(\" \")) > 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "urban-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "list = ['The Notorious B.I.G.', 'Ice Cube', 'Nas', '2Pac', 'Method Man', 'Eminem',\n",
    "        'Ghostface Killah', 'Snoop Dogg', 'DMX', 'Dr. Dre', 'GZA', 'RZA']\n",
    "df = df[df['artist_name'].isin(list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "extensive-checkout",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Eminem                  8377\n",
       "Ice Cube                4381\n",
       "Nas                     3821\n",
       "2Pac                    3775\n",
       "Method Man              3331\n",
       "Ghostface Killah        3063\n",
       "The Notorious B.I.G.    2695\n",
       "Snoop Dogg              2626\n",
       "DMX                     2562\n",
       "Dr. Dre                 2235\n",
       "GZA                     2033\n",
       "RZA                     1762\n",
       "Name: artist_name, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['artist_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "early-frontier",
   "metadata": {},
   "outputs": [],
   "source": [
    "west_coast_list = ['Ice Cube', '2Pac', 'Eminem', 'Snoop Dogg', 'Dr. Dre']\n",
    "\n",
    "df[\"coast\"] = [\"W\" if el in west_coast_list else \"E\" for el in df[\"artist_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "everyday-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['artist_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "automotive-asbestos",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line</th>\n",
       "      <th>coast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38489</th>\n",
       "      <td>Why a motherfuckin' brother is hard to find</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3834</th>\n",
       "      <td>Come take a journey through my mind's eye</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72277</th>\n",
       "      <td>I go somewhere, don't remember how I came</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51237</th>\n",
       "      <td>Of rap, to take it to the next level, boost it</td>\n",
       "      <td>W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191965</th>\n",
       "      <td>The eightball murder verse, freestyle or rehea...</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     line coast\n",
       "38489         Why a motherfuckin' brother is hard to find     W\n",
       "3834            Come take a journey through my mind's eye     W\n",
       "72277           I go somewhere, don't remember how I came     E\n",
       "51237      Of rap, to take it to the next level, boost it     W\n",
       "191965  The eightball murder verse, freestyle or rehea...     E"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "becoming-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_features = df['line']\n",
    "lyrics_labels = df.pop('coast')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "chemical-wrapping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38489     W\n",
       "3834      W\n",
       "72277     E\n",
       "51237     W\n",
       "191965    E\n",
       "         ..\n",
       "186340    E\n",
       "79793     W\n",
       "49070     W\n",
       "3438      W\n",
       "67590     E\n",
       "Name: coast, Length: 40661, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "renewable-following",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E', 'W'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(lyrics_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "honey-brunei",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(lyrics_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "considered-wiring",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_labels = lyrics_labels.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "optimum-valuation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'E', 1: 'W'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_ids = dict(enumerate(lyrics_labels.cat.categories))\n",
    "artist_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "filled-argentina",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_labels = lyrics_labels.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "adult-counter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38489     1\n",
       "3834      1\n",
       "72277     0\n",
       "51237     1\n",
       "191965    0\n",
       "         ..\n",
       "186340    0\n",
       "79793     1\n",
       "49070     1\n",
       "3438      1\n",
       "67590     0\n",
       "Length: 40661, dtype: int8"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "hazardous-radio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(lyrics_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "concerned-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_ds = tf.data.Dataset.from_tensor_slices((lyrics_features, lyrics_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "convenient-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 38000\n",
    "BATCH_SIZE = 64\n",
    "VALIDATION_SIZE = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "circular-colorado",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line:  b\"With wild imaginings that you can't discuss\"\n",
      "Coast: 0\n",
      "Line:  b'This beat is cray-cray, Ray J, H-A-H-A-H-A'\n",
      "Coast: 1\n",
      "Line:  b'The police are gonna have to come and get me'\n",
      "Coast: 1\n",
      "Line:  b\"And now I see you on a video with Michel'le\"\n",
      "Coast: 1\n",
      "Line:  b\"Eazy-E's, Ice Cube's, and D.O.C.'s\"\n",
      "Coast: 1\n",
      "Line:  b'Gold around his neck in 14 K heaven'\n",
      "Coast: 1\n",
      "Line:  b\"How it's Christmas time and my rhyme's steady bumpin'\"\n",
      "Coast: 1\n",
      "Line:  b\"I ain't know whether to cry or just, try to laugh it off\"\n",
      "Coast: 0\n",
      "Line:  b\"You sold me your soul when you didn't say no\"\n",
      "Coast: 0\n",
      "Line:  b'If I sell a brick I can buy a house'\n",
      "Coast: 1\n"
     ]
    }
   ],
   "source": [
    "all_labeled_data = lyrics_ds.shuffle(\n",
    "    BUFFER_SIZE, reshuffle_each_iteration=False)\n",
    "\n",
    "for text, label in all_labeled_data.take(10):\n",
    "  print(\"Line: \", text.numpy())\n",
    "  print(\"Coast:\", label.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dried-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "def configure_dataset(dataset):\n",
    "  return dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-payroll",
   "metadata": {},
   "source": [
    "### PROCESSING DATA FOR CNN CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "sound-listening",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf_text.UnicodeScriptTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fiscal-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, unused_label):\n",
    "  lower_case = tf_text.case_fold_utf8(text)\n",
    "  return tokenizer.tokenize(lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dedicated-uruguay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\korni\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
      "Instructions for updating:\n",
      "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n"
     ]
    }
   ],
   "source": [
    "tokenized_ds = all_labeled_data.map(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "casual-metropolitan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:  [b'with' b'wild' b'imaginings' b'that' b'you' b'can' b\"'\" b't' b'discuss']\n",
      "Tokens:  [b'this' b'beat' b'is' b'cray' b'-' b'cray' b',' b'ray' b'j' b',' b'h'\n",
      " b'-' b'a' b'-' b'h' b'-' b'a' b'-' b'h' b'-' b'a']\n",
      "Tokens:  [b'the' b'police' b'are' b'gonna' b'have' b'to' b'come' b'and' b'get'\n",
      " b'me']\n",
      "Tokens:  [b'and' b'now' b'i' b'see' b'you' b'on' b'a' b'video' b'with' b'michel'\n",
      " b\"'\" b'le']\n",
      "Tokens:  [b'eazy' b'-' b'e' b\"'\" b's' b',' b'ice' b'cube' b\"'\" b's' b',' b'and'\n",
      " b'd' b'.' b'o' b'.' b'c' b\".'\" b's']\n"
     ]
    }
   ],
   "source": [
    "for text_batch in tokenized_ds.take(5):\n",
    "  print(\"Tokens: \", text_batch.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "black-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "MAX_SEQUENCE_LENGTH = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "executive-highland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size:  10000\n",
      "First five vocab entries: [b',', b\"'\", b'the', b'i', b'a']\n"
     ]
    }
   ],
   "source": [
    "tokenized_ds = configure_dataset(tokenized_ds)\n",
    "\n",
    "vocab_dict = collections.defaultdict(lambda: 0)\n",
    "for toks in tokenized_ds.as_numpy_iterator():\n",
    "  for tok in toks:\n",
    "    vocab_dict[tok] += 1\n",
    "\n",
    "vocab = sorted(vocab_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "vocab = [token for token, count in vocab]\n",
    "vocab = vocab[:VOCAB_SIZE]\n",
    "vocab_size = len(vocab)\n",
    "print(\"Vocab size: \", vocab_size)\n",
    "print(\"First five vocab entries:\", vocab[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bulgarian-simon",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = vocab\n",
    "values = range(2, len(vocab) + 2)  # reserve 0 for padding, 1 for OOV\n",
    "\n",
    "init = tf.lookup.KeyValueTensorInitializer(\n",
    "    keys, values, key_dtype=tf.string, value_dtype=tf.int64)\n",
    "\n",
    "num_oov_buckets = 1\n",
    "vocab_table = tf.lookup.StaticVocabularyTable(init, num_oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "characteristic-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, label):\n",
    "  standardized = tf_text.case_fold_utf8(text)\n",
    "  tokenized = tokenizer.tokenize(standardized)\n",
    "  vectorized = vocab_table.lookup(tokenized)\n",
    "  return vectorized, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "champion-traveler",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  b\"With wild imaginings that you can't discuss\"\n",
      "Vectorized sentence:  [   20   539 10000    16     7    40     3    14  3667]\n"
     ]
    }
   ],
   "source": [
    "example_text, example_label = next(iter(all_labeled_data))\n",
    "print(\"Sentence: \", example_text.numpy())\n",
    "vectorized_text, example_label = preprocess_text(example_text, example_label)\n",
    "print(\"Vectorized sentence: \", vectorized_text.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "mounted-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_encoded_data = all_labeled_data.map(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "lovely-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = all_encoded_data.skip(VALIDATION_SIZE).shuffle(BUFFER_SIZE)\n",
    "validation_data = all_encoded_data.take(VALIDATION_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "voluntary-wyoming",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.padded_batch(BATCH_SIZE)\n",
    "validation_data = validation_data.padded_batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "incorporate-barcelona",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text batch shape:  (64, 21)\n",
      "Label batch shape:  (64,)\n",
      "First text example:  tf.Tensor(\n",
      "[   20   539 10000    16     7    40     3    14  3667     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0], shape=(21,), dtype=int64)\n",
      "First label example:  tf.Tensor(0, shape=(), dtype=int8)\n"
     ]
    }
   ],
   "source": [
    "sample_text, sample_labels = next(iter(validation_data))\n",
    "print(\"Text batch shape: \", sample_text.shape)\n",
    "print(\"Label batch shape: \", sample_labels.shape)\n",
    "print(\"First text example: \", sample_text[0])\n",
    "print(\"First label example: \", sample_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "compound-tournament",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "blocked-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = configure_dataset(train_data)\n",
    "validation_data = configure_dataset(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-fiber",
   "metadata": {},
   "source": [
    "## TRAIN MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-share",
   "metadata": {},
   "source": [
    "### CLASSIFIER 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "racial-tennis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size):\n",
    "#     model = tf.keras.Sequential([\n",
    "#         layers.Embedding(vocab_size, 64, mask_zero=True),\n",
    "#         layers.Conv1D(64, 5, padding=\"valid\", activation=\"relu\", strides=2),\n",
    "#         layers.GlobalMaxPooling1D(),\n",
    "#         layers.Dense(num_labels)\n",
    "#     ])\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Embedding(vocab_size, 64, mask_zero=True),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "behind-fellow",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "589/589 [==============================] - 53s 28ms/step - loss: 0.6655 - accuracy: 0.5189 - val_loss: 0.6158 - val_accuracy: 0.6390\n",
      "Epoch 2/20\n",
      "589/589 [==============================] - 11s 19ms/step - loss: 0.5824 - accuracy: 0.6646 - val_loss: 0.5849 - val_accuracy: 0.6753\n",
      "Epoch 3/20\n",
      "589/589 [==============================] - 11s 18ms/step - loss: 0.5288 - accuracy: 0.7119 - val_loss: 0.5785 - val_accuracy: 0.6870\n",
      "Epoch 4/20\n",
      "589/589 [==============================] - 11s 18ms/step - loss: 0.4961 - accuracy: 0.7395 - val_loss: 0.5839 - val_accuracy: 0.6933\n",
      "Epoch 5/20\n",
      "589/589 [==============================] - 10s 18ms/step - loss: 0.4746 - accuracy: 0.7517 - val_loss: 0.5951 - val_accuracy: 0.6930\n",
      "Epoch 6/20\n",
      "589/589 [==============================] - 10s 18ms/step - loss: 0.4593 - accuracy: 0.7611 - val_loss: 0.6090 - val_accuracy: 0.6897\n",
      "Epoch 7/20\n",
      "589/589 [==============================] - 10s 18ms/step - loss: 0.4471 - accuracy: 0.7687 - val_loss: 0.6243 - val_accuracy: 0.6947\n",
      "Epoch 8/20\n",
      "589/589 [==============================] - 10s 18ms/step - loss: 0.4399 - accuracy: 0.7725 - val_loss: 0.6409 - val_accuracy: 0.6927\n",
      "Epoch 9/20\n",
      "589/589 [==============================] - 11s 18ms/step - loss: 0.4328 - accuracy: 0.7757 - val_loss: 0.6562 - val_accuracy: 0.6937\n",
      "Epoch 10/20\n",
      "589/589 [==============================] - 11s 18ms/step - loss: 0.4268 - accuracy: 0.7793 - val_loss: 0.6722 - val_accuracy: 0.6917\n",
      "Epoch 11/20\n",
      "589/589 [==============================] - 10s 18ms/step - loss: 0.4235 - accuracy: 0.7809 - val_loss: 0.6877 - val_accuracy: 0.6903\n",
      "Epoch 12/20\n",
      "589/589 [==============================] - 10s 18ms/step - loss: 0.4183 - accuracy: 0.7843 - val_loss: 0.7029 - val_accuracy: 0.6853\n",
      "Epoch 13/20\n",
      "589/589 [==============================] - 11s 18ms/step - loss: 0.4151 - accuracy: 0.7825 - val_loss: 0.7184 - val_accuracy: 0.6847\n",
      "Epoch 14/20\n",
      "589/589 [==============================] - 10s 18ms/step - loss: 0.4127 - accuracy: 0.7873 - val_loss: 0.7339 - val_accuracy: 0.6820\n",
      "Epoch 15/20\n",
      "589/589 [==============================] - 11s 18ms/step - loss: 0.4104 - accuracy: 0.7890 - val_loss: 0.7478 - val_accuracy: 0.6817\n",
      "Epoch 16/20\n",
      "589/589 [==============================] - 10s 17ms/step - loss: 0.4081 - accuracy: 0.7902 - val_loss: 0.7618 - val_accuracy: 0.6810\n",
      "Epoch 17/20\n",
      "589/589 [==============================] - 11s 18ms/step - loss: 0.4061 - accuracy: 0.7897 - val_loss: 0.7768 - val_accuracy: 0.6810\n",
      "Epoch 18/20\n",
      "589/589 [==============================] - 11s 18ms/step - loss: 0.4047 - accuracy: 0.7916 - val_loss: 0.7897 - val_accuracy: 0.6817\n",
      "Epoch 19/20\n",
      "589/589 [==============================] - 11s 19ms/step - loss: 0.4025 - accuracy: 0.7917 - val_loss: 0.8022 - val_accuracy: 0.6800\n",
      "Epoch 20/20\n",
      "589/589 [==============================] - 11s 20ms/step - loss: 0.4010 - accuracy: 0.7916 - val_loss: 0.8146 - val_accuracy: 0.6827\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocab_size=vocab_size)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "history = model.fit(train_data, validation_data=validation_data, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "atmospheric-houston",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 2s 3ms/step - loss: 0.8146 - accuracy: 0.6827\n",
      "Loss:  0.8145785331726074\n",
      "Accuracy: 68.27%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(validation_data)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: {:2.2%}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "soviet-secretariat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: coast_classificer_1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('coast_classificer_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joint-computer",
   "metadata": {},
   "source": [
    "### CLASSIFIER 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "stupid-ordinary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Embedding(vocab_size, 16),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.GlobalAveragePooling1D(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1)])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "modern-plasma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "589/589 [==============================] - 8s 10ms/step - loss: 0.6840 - accuracy: 0.4781 - val_loss: 0.6520 - val_accuracy: 0.5390\n",
      "Epoch 2/20\n",
      "589/589 [==============================] - 5s 9ms/step - loss: 0.6375 - accuracy: 0.5763 - val_loss: 0.6280 - val_accuracy: 0.5990\n",
      "Epoch 3/20\n",
      "589/589 [==============================] - 6s 10ms/step - loss: 0.6036 - accuracy: 0.6285 - val_loss: 0.6100 - val_accuracy: 0.6303\n",
      "Epoch 4/20\n",
      "589/589 [==============================] - 5s 9ms/step - loss: 0.5741 - accuracy: 0.6628 - val_loss: 0.5964 - val_accuracy: 0.6510\n",
      "Epoch 5/20\n",
      "589/589 [==============================] - 6s 10ms/step - loss: 0.5495 - accuracy: 0.6866 - val_loss: 0.5870 - val_accuracy: 0.6657\n",
      "Epoch 6/20\n",
      "589/589 [==============================] - 6s 10ms/step - loss: 0.5283 - accuracy: 0.7067 - val_loss: 0.5814 - val_accuracy: 0.6727\n",
      "Epoch 7/20\n",
      "589/589 [==============================] - 6s 9ms/step - loss: 0.5114 - accuracy: 0.7250 - val_loss: 0.5788 - val_accuracy: 0.6783\n",
      "Epoch 8/20\n",
      "589/589 [==============================] - 5s 9ms/step - loss: 0.4958 - accuracy: 0.7349 - val_loss: 0.5788 - val_accuracy: 0.6833\n",
      "Epoch 9/20\n",
      "589/589 [==============================] - 5s 9ms/step - loss: 0.4846 - accuracy: 0.7417 - val_loss: 0.5809 - val_accuracy: 0.6870\n",
      "Epoch 10/20\n",
      "589/589 [==============================] - 6s 10ms/step - loss: 0.4748 - accuracy: 0.7498 - val_loss: 0.5844 - val_accuracy: 0.6857\n",
      "Epoch 11/20\n",
      "589/589 [==============================] - 5s 9ms/step - loss: 0.4657 - accuracy: 0.7559 - val_loss: 0.5885 - val_accuracy: 0.6880\n",
      "Epoch 12/20\n",
      "589/589 [==============================] - 6s 9ms/step - loss: 0.4577 - accuracy: 0.7617 - val_loss: 0.5937 - val_accuracy: 0.6857\n",
      "Epoch 13/20\n",
      "589/589 [==============================] - 6s 10ms/step - loss: 0.4509 - accuracy: 0.7655 - val_loss: 0.6003 - val_accuracy: 0.6837\n",
      "Epoch 14/20\n",
      "589/589 [==============================] - 6s 10ms/step - loss: 0.4440 - accuracy: 0.7694 - val_loss: 0.6058 - val_accuracy: 0.6883\n",
      "Epoch 15/20\n",
      "589/589 [==============================] - 6s 10ms/step - loss: 0.4403 - accuracy: 0.7720 - val_loss: 0.6127 - val_accuracy: 0.6847\n",
      "Epoch 16/20\n",
      "589/589 [==============================] - 6s 10ms/step - loss: 0.4358 - accuracy: 0.7742 - val_loss: 0.6195 - val_accuracy: 0.6830\n",
      "Epoch 17/20\n",
      "589/589 [==============================] - 5s 9ms/step - loss: 0.4328 - accuracy: 0.7761 - val_loss: 0.6268 - val_accuracy: 0.6833\n",
      "Epoch 18/20\n",
      "589/589 [==============================] - 5s 9ms/step - loss: 0.4277 - accuracy: 0.7791 - val_loss: 0.6355 - val_accuracy: 0.6813\n",
      "Epoch 19/20\n",
      "589/589 [==============================] - 6s 9ms/step - loss: 0.4245 - accuracy: 0.7827 - val_loss: 0.6436 - val_accuracy: 0.6813\n",
      "Epoch 20/20\n",
      "589/589 [==============================] - 6s 10ms/step - loss: 0.4209 - accuracy: 0.7825 - val_loss: 0.6511 - val_accuracy: 0.6820\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocab_size=vocab_size)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "history = model.fit(train_data, validation_data=validation_data, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "suitable-moore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 2s 3ms/step - loss: 0.6511 - accuracy: 0.6820\n",
      "Loss:  0.6511495113372803\n",
      "Accuracy: 68.20%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(validation_data)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: {:2.2%}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bibliographic-plaintiff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: coast_classificer_1_1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('coast_classificer_1_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-delay",
   "metadata": {},
   "source": [
    "### CLASSIFIER 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "responsible-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        layers.Embedding(vocab_size, 64, mask_zero=True),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Conv1D(64, 5, padding=\"valid\", activation=\"relu\", strides=2),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.GlobalMaxPooling1D(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "pediatric-wonder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "589/589 [==============================] - 16s 22ms/step - loss: 0.6574 - accuracy: 0.5449 - val_loss: 0.5883 - val_accuracy: 0.6537\n",
      "Epoch 2/20\n",
      "589/589 [==============================] - 12s 21ms/step - loss: 0.5428 - accuracy: 0.7012 - val_loss: 0.5814 - val_accuracy: 0.6833\n",
      "Epoch 3/20\n",
      "589/589 [==============================] - 11s 19ms/step - loss: 0.4610 - accuracy: 0.7638 - val_loss: 0.6166 - val_accuracy: 0.6840\n",
      "Epoch 4/20\n",
      "589/589 [==============================] - 11s 19ms/step - loss: 0.3840 - accuracy: 0.8127 - val_loss: 0.6834 - val_accuracy: 0.6783\n",
      "Epoch 5/20\n",
      "589/589 [==============================] - 11s 19ms/step - loss: 0.3229 - accuracy: 0.8475 - val_loss: 0.7569 - val_accuracy: 0.6737\n",
      "Epoch 6/20\n",
      "589/589 [==============================] - 11s 19ms/step - loss: 0.2723 - accuracy: 0.8731 - val_loss: 0.8426 - val_accuracy: 0.6723\n",
      "Epoch 7/20\n",
      "589/589 [==============================] - 12s 20ms/step - loss: 0.2385 - accuracy: 0.8880 - val_loss: 0.9262 - val_accuracy: 0.6753\n",
      "Epoch 8/20\n",
      "589/589 [==============================] - 11s 19ms/step - loss: 0.2125 - accuracy: 0.9029 - val_loss: 1.0234 - val_accuracy: 0.6687\n",
      "Epoch 9/20\n",
      "589/589 [==============================] - 13s 21ms/step - loss: 0.1894 - accuracy: 0.9127 - val_loss: 1.1090 - val_accuracy: 0.6647\n",
      "Epoch 10/20\n",
      "589/589 [==============================] - 13s 22ms/step - loss: 0.1716 - accuracy: 0.9191 - val_loss: 1.1977 - val_accuracy: 0.6710\n",
      "Epoch 11/20\n",
      "589/589 [==============================] - 13s 22ms/step - loss: 0.1599 - accuracy: 0.9264 - val_loss: 1.2778 - val_accuracy: 0.6693\n",
      "Epoch 12/20\n",
      "589/589 [==============================] - 13s 22ms/step - loss: 0.1496 - accuracy: 0.9321 - val_loss: 1.3472 - val_accuracy: 0.6677\n",
      "Epoch 13/20\n",
      "589/589 [==============================] - 13s 22ms/step - loss: 0.1363 - accuracy: 0.9378 - val_loss: 1.4395 - val_accuracy: 0.6697\n",
      "Epoch 14/20\n",
      "589/589 [==============================] - 13s 23ms/step - loss: 0.1287 - accuracy: 0.9408 - val_loss: 1.4850 - val_accuracy: 0.6693\n",
      "Epoch 15/20\n",
      "589/589 [==============================] - 13s 22ms/step - loss: 0.1210 - accuracy: 0.9442 - val_loss: 1.5972 - val_accuracy: 0.6663\n",
      "Epoch 16/20\n",
      "589/589 [==============================] - 12s 21ms/step - loss: 0.1202 - accuracy: 0.9435 - val_loss: 1.6314 - val_accuracy: 0.6683\n",
      "Epoch 17/20\n",
      "589/589 [==============================] - 13s 22ms/step - loss: 0.1171 - accuracy: 0.9478 - val_loss: 1.6799 - val_accuracy: 0.6673\n",
      "Epoch 18/20\n",
      "589/589 [==============================] - 13s 22ms/step - loss: 0.1080 - accuracy: 0.9524 - val_loss: 1.7316 - val_accuracy: 0.6660\n",
      "Epoch 19/20\n",
      "589/589 [==============================] - 13s 22ms/step - loss: 0.1048 - accuracy: 0.9526 - val_loss: 1.8099 - val_accuracy: 0.6697\n",
      "Epoch 20/20\n",
      "589/589 [==============================] - 13s 22ms/step - loss: 0.1021 - accuracy: 0.9559 - val_loss: 1.8632 - val_accuracy: 0.6643\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocab_size=vocab_size)\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy'])\n",
    "history = model.fit(train_data, validation_data=validation_data, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "soviet-viking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 2s 4ms/step - loss: 1.8632 - accuracy: 0.6643\n",
      "Loss:  1.8632304668426514\n",
      "Accuracy: 66.43%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(validation_data)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: {:2.2%}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "informative-arrangement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: coast_classificer_1_2\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('coast_classificer_1_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-stadium",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
